{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b450b7ea",
   "metadata": {},
   "source": [
    "Metin Temizleme (Text cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Örnek metin\n",
    "text = \"This is a sample tezt! Instantiation Nrumbers: 1234? Symbols: %$#@&.\"\n",
    "\n",
    "# Temizleme işlemi: Sadece harfler ve boşluklar bırakılır\n",
    "cleaned_text = re.sub(r'[^a-zA-ZçğıöşüÇĞİÖŞÜ\\s]', '', text)\n",
    "print(\"Temizlenmiş metin:\", cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9172c",
   "metadata": {},
   "source": [
    "Simgeleştirme (Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# sadece bir kez yapılmalı\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Kelimelere bölme\n",
    "word_tokens = word_tokenize(cleaned_text)\n",
    "print(\"Kelimeler:\", word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeaafda",
   "metadata": {},
   "source": [
    "Büyük Harfleri Küçük Harflere Dönüştürme (Lowercasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Küçük harfe çevirme\n",
    "lower_tokens = [word.lower() for word in word_tokens]\n",
    "print(\"Küçük harf kelimeler:\", lower_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ef07f",
   "metadata": {},
   "source": [
    "Durak Kelimelerin Kaldırılması (Stopword Removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk'nin stopwords veri kümesini indiriyoruz (sadece bir kez yapılmalı)\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Stopword listesini alıyoruz\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Durak kelimeleri çıkarma\n",
    "filtered_tokens = [word for word in lower_tokens if word not in stop_words]\n",
    "print(\"Durak kelimeler çıkarılmış metin:\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc808db7",
   "metadata": {},
   "source": [
    " İmla ve Yazım Düzeltme (Spell Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c90493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(language='en')\n",
    "\n",
    "# Kelime düzeltme\n",
    "corrected_tokens = [spell.correction(word) for word in filtered_tokens]\n",
    "print(\"Düzeltilmiş metin:\", corrected_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0655cb",
   "metadata": {},
   "source": [
    "Gövdeleme (Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c060e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# İngilizce için PorterStemmer'ı başlatıyoruz\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Gövde bulma işlemi\n",
    "stemmed_text = [stemmer.stem(word) for word in corrected_tokens]\n",
    "print(\"Gövdelerine ayrılmış metin:\", stemmed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e163380",
   "metadata": {},
   "source": [
    "Başsözcükleştirme (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# NLTK veri dosyalarını indir\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Lemmatizer'ı başlat\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Kelimelerin lemmatization işlemi\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in corrected_tokens]\n",
    "\n",
    "print(\"Lemmatized kelimeler:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4b219",
   "metadata": {},
   "source": [
    "ÖDEV\n",
    "\n",
    "Metin önişleme adımlarını 'Türkçe' için gerçekleştiriniz.\n",
    "\n",
    "* Zemberek, TMoST, VNLP, Stanza gibi NLP kütüphanelerini kullanabilirsiniz.\n",
    "* Kodlarınız metin dosyaları üzerinde çalışabilmelidir.\n",
    "* Pipeline biçiminde girdi olarak ham metin verilip çıktı olarak gövdelenmiş veya başsözcükleştirilmiş metin bir dosyaya yazdırılmalıdır.\n",
    "* Ödevi bireysel yapınız."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
