{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0250f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import string\n",
    "import math\n",
    "\n",
    "# Gerekli nltk verilerini indirme\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Metin dosyasını okuma\n",
    "with open(\"odtu_derlemi.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    metin = file.read()\n",
    "\n",
    "# Metni kelime seviyesinde tokenize et\n",
    "kelimeler = nltk.word_tokenize(metin.lower())\n",
    "\n",
    "# Noktalama işaretlerinden kurtulma\n",
    "kelimeler = [kelime for kelime in kelimeler if kelime not in string.punctuation]\n",
    "\n",
    "# 2-gram (Bigram) modelini oluştur\n",
    "bigramlar = list(ngrams(kelimeler, 2))\n",
    "\n",
    "# Bigramların frekansını hesapla\n",
    "bigram_freq = Counter(bigramlar)\n",
    "\n",
    "# Unigramların frekansını hesapla\n",
    "unigram_freq = Counter(kelimeler)\n",
    "\n",
    "# Toplam unigram ve bigram sayısını al\n",
    "toplam_unigram = sum(unigram_freq.values())\n",
    "toplam_bigram = sum(bigram_freq.values())\n",
    "\n",
    "# Verilen bir cümlenin bigram zinciri olasılığını hesaplama\n",
    "def cumlenin_olasiligini_hesapla(cumle):\n",
    "    # Cümleyi tokenize et ve noktalama işaretlerinden kurtul\n",
    "    kelimeler = nltk.word_tokenize(cumle.lower())\n",
    "    kelimeler = [kelime for kelime in kelimeler if kelime not in string.punctuation]\n",
    "    \n",
    "    # İlk kelimenin unigram olasılığı\n",
    "    ilk_kelime = kelimeler[0]\n",
    "    if ilk_kelime in unigram_freq:\n",
    "        olasilik = unigram_freq[ilk_kelime] / toplam_unigram\n",
    "    else:\n",
    "        olasilik = 1 / toplam_unigram  # Eğer ilk kelime yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    # Sonraki kelimeler için bigram olasılıklarını çarp\n",
    "    for i in range(1, len(kelimeler)):\n",
    "        onceki_kelime = kelimeler[i - 1]\n",
    "        simdiki_kelime = kelimeler[i]\n",
    "        bigram = (onceki_kelime, simdiki_kelime)\n",
    "        \n",
    "        if bigram in bigram_freq:\n",
    "            olasilik *= bigram_freq[bigram] / unigram_freq[onceki_kelime]\n",
    "        else:\n",
    "            olasilik *= 1 / toplam_bigram  # Eğer bigram yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    return olasilik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cümlesi\n",
    "cumle = \"hafta sonu sinemaya gidelim\"\n",
    "olasilik = cumlenin_olasiligini_hesapla(cumle)\n",
    "\n",
    "print(f\"'{cumle}' cümlesinin olasılığı: {olasilik}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f684054",
   "metadata": {},
   "source": [
    "Yukarıda Markov zinciri formülü yardımıyla bigram'leri kullanarak cümle olasılıklarını hesapladık. Ancak bigram olasılıklarını çarptığımız için daha uzun cümlelerin olasılıkları daha düşük olacaktır. Bu handikaptan kurtulmak için log-olasılıkları hesaplayalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ea896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verilen bir cümlenin logaritmik bigram zinciri olasılığını hesaplama\n",
    "def cumlenin_log_olasiligini_hesapla(cumle):\n",
    "    # Cümleyi tokenize et ve noktalama işaretlerinden kurtul\n",
    "    kelimeler = nltk.word_tokenize(cumle.lower())\n",
    "    kelimeler = [kelime for kelime in kelimeler if kelime not in string.punctuation]\n",
    "    \n",
    "    # İlk kelimenin unigram olasılığı\n",
    "    ilk_kelime = kelimeler[0]\n",
    "    if ilk_kelime in unigram_freq:\n",
    "        log_olasilik = math.log(unigram_freq[ilk_kelime] / toplam_unigram)\n",
    "    else:\n",
    "        log_olasilik = math.log(1 / toplam_unigram)  # Eğer ilk kelime yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    # Sonraki kelimeler için bigram log olasılıklarını toplama\n",
    "    for i in range(1, len(kelimeler)):\n",
    "        onceki_kelime = kelimeler[i - 1]\n",
    "        simdiki_kelime = kelimeler[i]\n",
    "        bigram = (onceki_kelime, simdiki_kelime)\n",
    "        \n",
    "        if bigram in bigram_freq:\n",
    "            log_olasilik += math.log(bigram_freq[bigram] / unigram_freq[onceki_kelime])\n",
    "        else:\n",
    "            log_olasilik += math.log(1 / toplam_bigram)  # Eğer bigram yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    return log_olasilik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360033f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test için bir dizi cümle\n",
    "cumleler = [\n",
    "    \"hafta sonu sinemaya gidelim\",\n",
    "    \"hafta sonu sinemaya gidersek\",\n",
    "    \"hafta sonu sinemaya gittik\",\n",
    "    \"hafta sonu sinemaya gideceğiz\"\n",
    "]\n",
    "\n",
    "# Her bir cümle için logaritmik olasılığı hesapla ve yazdır\n",
    "for cumle in cumleler:\n",
    "    log_olasilik = cumlenin_log_olasiligini_hesapla(cumle)\n",
    "    print(f\"'{cumle}' cümlesinin logaritmik olasılığı: {log_olasilik}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db947de",
   "metadata": {},
   "source": [
    "herhangi bir ikilinin ikili sıklık listesinde olup olmadığına bakabiliriz, listede olmayan ikililer cümlenin olasılığını düşürür: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17411775",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = (\"sinemaya\", \"gidelim\")\n",
    "        \n",
    "if bigram in bigram_freq:\n",
    "    print(\"var\")\n",
    "else:\n",
    "    print(\"yok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31457299",
   "metadata": {},
   "source": [
    "n-gram dil modellerini kullanarak bir kelimeden sonra gelebilecek en olası kelimeyi bulabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bee63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonraki_kelimeyi_tahmin_et(baslangic_kelimesi, bigram_freq):\n",
    "    olasi_bigramlar = {bigram: freq for bigram, freq in bigram_freq.items() if bigram[0] == baslangic_kelimesi}\n",
    "    en_olasi_bigram = max(olasi_bigramlar, key=olasi_bigramlar.get) if olasi_bigramlar else None\n",
    "    if en_olasi_bigram:\n",
    "        return en_olasi_bigram[1]\n",
    "    return None\n",
    "\n",
    "baslangic = \"üniversite\"\n",
    "sonraki_kelime = sonraki_kelimeyi_tahmin_et(baslangic, bigram_freq)\n",
    "print(f\"'{baslangic}' kelimesinden sonra en olası kelime: {sonraki_kelime}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec116651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metin_olustur(baslangic_kelime, bigram_freq, n=10):\n",
    "    metin = [baslangic_kelime]\n",
    "    for _ in range(n):\n",
    "        sonraki_kelime = sonraki_kelimeyi_tahmin_et(metin[-1], bigram_freq)\n",
    "        if sonraki_kelime:\n",
    "            metin.append(sonraki_kelime)\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(metin)\n",
    "\n",
    "baslangic = \"üniversite\"\n",
    "uretilen_metin = metin_olustur(baslangic, bigram_freq)\n",
    "print(f\"Oluşturulan metin: {uretilen_metin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e1777",
   "metadata": {},
   "source": [
    "Metin üretiminde özellikle deterministik yaklaşımlar kullanıldığında (yani her zaman en yüksek olasılıklı kelimenin seçilmesi) sürekli aynı kelime dizisine ulaşılabilir. Bundan kaçınmak için aşağıdaki gibi rastsallık eklenebilir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sonraki_kelimeyi_rastsal_tahmin_et(baslangic_kelimesi, bigram_freq):\n",
    "    olasi_bigramlar = {bigram: freq for bigram, freq in bigram_freq.items() if bigram[0] == baslangic_kelimesi}\n",
    "    \n",
    "    if not olasi_bigramlar:\n",
    "        return None\n",
    "    \n",
    "    bigramlar = list(olasi_bigramlar.keys())\n",
    "    frekanslar = list(olasi_bigramlar.values())\n",
    "    \n",
    "    # Bigram olasılıklarını normalize etme\n",
    "    toplam_frekans = sum(frekanslar)\n",
    "    olasiliklar = [freq / toplam_frekans for freq in frekanslar]\n",
    "    \n",
    "    # Olasılıklara dayalı rastgele seçim yap\n",
    "    secilen_bigram = random.choices(bigramlar, weights=olasiliklar, k=1)[0]\n",
    "    return secilen_bigram[1]\n",
    "\n",
    "# Rastsal kelime seçimi ile metin oluşturma\n",
    "def metin_olustur_rastsal(baslangic_kelime, bigram_freq, n=10):\n",
    "    metin = [baslangic_kelime]\n",
    "    for _ in range(n):\n",
    "        sonraki_kelime = sonraki_kelimeyi_rastsal_tahmin_et(metin[-1], bigram_freq)\n",
    "        if sonraki_kelime:\n",
    "            metin.append(sonraki_kelime)\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(metin)\n",
    "\n",
    "# Test için metin oluşturma\n",
    "baslangic = \"üniversite\"\n",
    "uretilen_metin = metin_olustur_rastsal(baslangic, bigram_freq)\n",
    "print(f\"Oluşturulan metin: {uretilen_metin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642ed08",
   "metadata": {},
   "source": [
    "N-gram modelleri yazım hatası olan kelimeleri düzeltebilir. Bir kelime yanlış yazıldığında, model bir kelimenin en çok hangi kelimeyle eşleştiğini bulabilir ve hatalı kelime yerine doğrusunu önerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77797962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hatalı bir kelimeyi düzeltmek için benzer kelimeleri bulma (Levenshtein mesafesi veya basit bir yakınlık ölçüsü kullanarak)\n",
    "def kelime_duzeltme(hatali_kelime, unigram_freq):\n",
    "    # Levenshtein mesafesi (hamming distance gibi) kullanmak daha gelişmiş olabilir, ancak burada basit bir benzerlik ölçüsü kullanıyoruz.\n",
    "    def benzerlik(kelime1, kelime2):\n",
    "        # Aynı uzunluktaki kelimeler daha olasıdır\n",
    "        if abs(len(kelime1) - len(kelime2)) > 2:\n",
    "            return 0\n",
    "        # Harflerin ne kadarının eşleştiğine bakarak basit bir benzerlik skoru verelim\n",
    "        return sum(1 for a, b in zip(kelime1, kelime2) if a == b)\n",
    "\n",
    "    # Tüm unigramlar içinde hatalı kelimeye en çok benzeyen kelimeleri bulalım\n",
    "    en_benzer_kelime = max(unigram_freq.keys(), key=lambda kelime: benzerlik(hatali_kelime, kelime))\n",
    "    return en_benzer_kelime\n",
    "\n",
    "# Test cümlesi: Hatalı bir kelime ile\n",
    "hatali_cumle = \"yarın hava sırak olacak\"\n",
    "cumledeki_kelime = \"sırak\"\n",
    "\n",
    "# Düzeltme önerisi\n",
    "duzeltilmis_kelime = kelime_duzeltme(cumledeki_kelime, unigram_freq)\n",
    "\n",
    "print(f\"Hatalı kelime: {cumledeki_kelime}, Düzeltme önerisi: {duzeltilmis_kelime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a947fdf",
   "metadata": {},
   "source": [
    "İmla düzeltme işleminde önceki ve sonraki kelimeyi hesaba katarsak model çok daha güçlü hale gelir:\n",
    "(Ayrıca iki kelime arasındaki harflerin birebir eşleşmesine bakarak basit bir benzerlik skoru hesaplama yerine Levenshtein mesafesini kullanalım)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilgili kütüphaneyi yüklemek için bu kodu bir kez çalıştırmalıyız:\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71891223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "# Hatalı bir kelimeyi düzelten fonksiyon (bağlama duyarlı)\n",
    "def kelime_duzeltme_bağlam(hatali_kelime, onceki_kelime, sonraki_kelime, unigram_freq, bigram_freq):\n",
    "    # Basit benzerlik ölçümü: Aynı uzunluktaki kelimeler daha olasıdır, harf eşleşmelerine bakıyoruz\n",
    "    def benzerlik(kelime1, kelime2):\n",
    "        if abs(len(kelime1) - len(kelime2)) > 2:\n",
    "            return 0\n",
    "        return sum(1 for a, b in zip(kelime1, kelime2) if a == b)\n",
    "\n",
    "    # Hataya en benzer kelimeleri bulalım\n",
    "    #olasi_duzeltmeler = sorted(unigram_freq.keys(), key=lambda kelime: benzerlik(hatali_kelime, kelime), reverse=True)[:50]\n",
    "    olasi_duzeltmeler = sorted(unigram_freq.keys(), key=lambda kelime: Levenshtein.distance(hatali_kelime, kelime))[:50]\n",
    "\n",
    "    # Bigram olasılıklarını hesaba katarak en olası kelimeyi seç\n",
    "    en_iyi_kelime = None\n",
    "    en_yuksek_olasilik = 0\n",
    "\n",
    "    for duzeltme in olasi_duzeltmeler:\n",
    "        # Önceki ve sonraki kelimelerle bigram oluşturma\n",
    "        bigram_olasilik = 1\n",
    "        if onceki_kelime and (onceki_kelime, duzeltme) in bigram_freq:\n",
    "            bigram_olasilik *= bigram_freq[(onceki_kelime, duzeltme)] / unigram_freq[onceki_kelime]\n",
    "        else:\n",
    "            bigram_olasilik *= 0.0001  # Eğer bigram yoksa küçük bir olasılık verelim\n",
    "        \n",
    "        if sonraki_kelime and (duzeltme, sonraki_kelime) in bigram_freq:\n",
    "            bigram_olasilik *= bigram_freq[(duzeltme, sonraki_kelime)] / unigram_freq[duzeltme]\n",
    "        else:\n",
    "            bigram_olasilik *= 0.0001  # Eğer bigram yoksa küçük bir olasılık verelim\n",
    "\n",
    "        # En yüksek olasılığa sahip kelimeyi seç\n",
    "        if bigram_olasilik > en_yuksek_olasilik:\n",
    "            en_yuksek_olasilik = bigram_olasilik\n",
    "            en_iyi_kelime = duzeltme\n",
    "        #print(duzeltme + \" \" + str(bigram_olasilik))\n",
    "    return en_iyi_kelime\n",
    "\n",
    "# Test cümlesi: Hatalı bir kelimeyle birlikte\n",
    "hatali_cumle = \"yarın hava sırak olacak\"\n",
    "cumle_tokens = nltk.word_tokenize(hatali_cumle.lower())\n",
    "\n",
    "# Hatalı kelime ve çevresindeki kelimeler\n",
    "target = 2\n",
    "hatali_kelime = cumle_tokens[target]\n",
    "onceki_kelime = cumle_tokens[target-1]\n",
    "sonraki_kelime = cumle_tokens[target+1]\n",
    "\n",
    "# Düzeltme önerisi\n",
    "duzeltilmis_kelime = kelime_duzeltme_bağlam(hatali_kelime, onceki_kelime, sonraki_kelime, unigram_freq, bigram_freq)\n",
    "\n",
    "print(f\"Hatalı kelime: {hatali_kelime}, Düzeltme önerisi: {duzeltilmis_kelime}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
