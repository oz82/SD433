{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb9166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import string\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbc582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İlk 10 Tokenize edilmiş kelime:  ['koca', 'bir', 'duvar', 'taşıyordun', 'yüreğinde', 'kimsenin', 'aşamayacağı', 'aşmaya', 'cesaret', 'bile']\n"
     ]
    }
   ],
   "source": [
    "# Metin dosyasını oku\n",
    "kelimeler = []\n",
    "\n",
    "with open(\"dosyalar\\odtu_derlemi.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        kelimeler.extend(nltk.word_tokenize(line.lower()))\n",
    "\n",
    "# Noktalama işaretlerinden kurtul\n",
    "punctuation_set = set(string.punctuation)\n",
    "kelimeler = [kelime for kelime in kelimeler if kelime not in punctuation_set]\n",
    "\n",
    "# İlk 10 kelime\n",
    "print(\"İlk 10 Tokenize edilmiş kelime: \", kelimeler[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd9785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2-gram (Bigram) modelini oluştur\n",
    "bigramlar = list(ngrams(kelimeler, 2))\n",
    "\n",
    "print(\"Bigramlar: \", bigramlar)\n",
    "\n",
    "# Bigramların sıklığını hesapla\n",
    "bigram_freq = Counter(bigramlar)\n",
    "\n",
    "# İlk 10 bigram\n",
    "print(\"İlk 10 Bigram: \", bigramlar[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95cdc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram: \"ya da\", Olasılık: 0.0010643019063084848\n",
      "Bigram: \"`` dedi\", Olasılık: 0.0007607861656726692\n",
      "Bigram: \"bir şey\", Olasılık: 0.0005675944031298064\n",
      "Bigram: \"`` diye\", Olasılık: 0.000406850869437812\n",
      "Bigram: \"böyle bir\", Olasılık: 0.00039137556029355164\n",
      "Bigram: \"hem de\", Olasılık: 0.00034744565046468357\n",
      "Bigram: \"yeni bir\", Olasılık: 0.00034445042933998804\n",
      "Bigram: \"ne kadar\", Olasılık: 0.0003434520222984229\n",
      "Bigram: \"büyük bir\", Olasılık: 0.00032597989907103215\n",
      "Bigram: \"bir de\", Olasılık: 0.0003234838814671192\n",
      "Bigram: \"bir süre\", Olasılık: 0.00030351574063581556\n",
      "Bigram: \"ben de\", Olasılık: 0.0003000213159903374\n",
      "Bigram: \"başka bir\", Olasılık: 0.00029253326317859853\n",
      "Bigram: \"ve bu\", Olasılık: 0.00028654282092920746\n",
      "Bigram: \"belki de\", Olasılık: 0.00028204998924216413\n",
      "Bigram: \"o zaman\", Olasılık: 0.00027006910474338194\n",
      "Bigram: \"genel başkanı\", Olasılık: 0.0002665746800979038\n",
      "Bigram: \"bu arada\", Olasılık: 0.00026357945897320824\n",
      "Bigram: \"diye konuştu\", Olasılık: 0.0002600850343277301\n",
      "Bigram: \"sonra da\", Olasılık: 0.0002371216723717309\n",
      "Bigram: \"bir gün\", Olasılık: 0.00023512485828860053\n",
      "Bigram: \"o kadar\", Olasılık: 0.00022863521251842686\n",
      "Bigram: \"bu kadar\", Olasılık: 0.00022813600899764425\n",
      "Bigram: \"daha çok\", Olasılık: 0.00022763680547686167\n",
      "Bigram: \"bu konuda\", Olasılık: 0.00022663839843529648\n",
      "Bigram: \"en büyük\", Olasılık: 0.0002261391949145139\n",
      "Bigram: \"söz konusu\", Olasılık: 0.00022414238083138353\n",
      "Bigram: \"o da\", Olasılık: 0.00022164636322747057\n",
      "Bigram: \"`` bu\", Olasılık: 0.00021765273506120985\n",
      "Bigram: \"daha önce\", Olasılık: 0.00021715353154042725\n",
      "Bigram: \"daha sonra\", Olasılık: 0.00021665432801964467\n",
      "Bigram: \"gibi bir\", Olasılık: 0.00021515671745729687\n",
      "Bigram: \"bu nedenle\", Olasılık: 0.00021016468224947096\n",
      "Bigram: \"önemli bir\", Olasılık: 0.00020567185056242764\n",
      "Bigram: \"bir başka\", Olasılık: 0.00020517264704164506\n",
      "Bigram: \"her şey\", Olasılık: 0.00020317583295851468\n",
      "Bigram: \"bu kez\", Olasılık: 0.00020167822239616691\n",
      "Bigram: \"prof dr\", Olasılık: 0.00019968140831303654\n",
      "Bigram: \"en çok\", Olasılık: 0.00019369096606364545\n",
      "Bigram: \"de bu\", Olasılık: 0.00018919813437660214\n",
      "Bigram: \"ilk kez\", Olasılık: 0.00018720132029347177\n",
      "Bigram: \"olduğu gibi\", Olasılık: 0.0001852045062103414\n",
      "Bigram: \"için de\", Olasılık: 0.00018470530268955882\n",
      "Bigram: \"de bir\", Olasılık: 0.00018270848860642844\n",
      "Bigram: \"hiçbir şey\", Olasılık: 0.00018171008156486326\n",
      "Bigram: \"daha da\", Olasılık: 0.00018121087804408068\n",
      "Bigram: \"ile ilgili\", Olasılık: 0.0001797132674817329\n",
      "Bigram: \"irak a\", Olasılık: 0.00017821565691938511\n",
      "Bigram: \"herhangi bir\", Olasılık: 0.00017671804635703735\n",
      "Bigram: \"ne de\", Olasılık: 0.00017272441819077663\n",
      "Bigram: \"bu yüzden\", Olasılık: 0.00017222521466999402\n",
      "Bigram: \"'' dedi\", Olasılık: 0.00017222521466999402\n",
      "Bigram: \"olmak üzere\", Olasılık: 0.00017072760410764625\n",
      "Bigram: \"da bir\", Olasılık: 0.00016873079002451588\n",
      "Bigram: \"da bu\", Olasılık: 0.00016673397594138553\n",
      "Bigram: \"bir an\", Olasılık: 0.00016573556889982034\n",
      "Bigram: \"’ da\", Olasılık: 0.00016423795833747255\n",
      "Bigram: \"olduğu için\", Olasılık: 0.00016373875481668997\n",
      "Bigram: \"bir yandan\", Olasılık: 0.0001632395512959074\n",
      "Bigram: \"bir kez\", Olasılık: 0.00016124273721277702\n",
      "Bigram: \"her şeyi\", Olasılık: 0.00016074353369199444\n",
      "Bigram: \"her zaman\", Olasılık: 0.00016024433017121183\n",
      "Bigram: \"pek çok\", Olasılık: 0.00015874671960886406\n",
      "Bigram: \"için bir\", Olasılık: 0.00015774831256729887\n",
      "Bigram: \"daha fazla\", Olasılık: 0.00015774831256729887\n",
      "Bigram: \"’ nin\", Olasılık: 0.0001567499055257337\n",
      "Bigram: \"ve bir\", Olasılık: 0.0001547530914426033\n",
      "Bigram: \"ama bu\", Olasılık: 0.00015375468440103815\n",
      "Bigram: \"yine de\", Olasılık: 0.00015375468440103815\n",
      "Bigram: \"yanı sıra\", Olasılık: 0.00015375468440103815\n",
      "Bigram: \"bir şekilde\", Olasılık: 0.00015325548088025555\n",
      "Bigram: \"çok daha\", Olasılık: 0.0001507594632763426\n",
      "Bigram: \"bir daha\", Olasılık: 0.0001497610562347774\n",
      "Bigram: \"bu tür\", Olasılık: 0.00014876264919321222\n",
      "Bigram: \"tayyip erdoğan\", Olasılık: 0.00014776424215164706\n",
      "Bigram: \"bu yana\", Olasılık: 0.00014726503863086445\n",
      "Bigram: \"yer alan\", Olasılık: 0.00014726503863086445\n",
      "Bigram: \"değil mi\", Olasılık: 0.00014676583511008187\n",
      "Bigram: \"şu anda\", Olasılık: 0.0001447690210269515\n",
      "Bigram: \"recep tayyip\", Olasılık: 0.00014277220694382112\n",
      "Bigram: \"çok iyi\", Olasılık: 0.00014227300342303854\n",
      "Bigram: \"1 milyon\", Olasılık: 0.00014227300342303854\n",
      "Bigram: \"bu da\", Olasılık: 0.00014177379990225596\n",
      "Bigram: \"daha iyi\", Olasılık: 0.0001397769858191256\n",
      "Bigram: \"’ ın\", Olasılık: 0.0001397769858191256\n",
      "Bigram: \"’ de\", Olasılık: 0.0001387785787775604\n",
      "Bigram: \"milyar dolar\", Olasılık: 0.00013827937525677782\n",
      "Bigram: \"’ in\", Olasılık: 0.00013827937525677782\n",
      "Bigram: \"milyon lira\", Olasılık: 0.00013778017173599522\n",
      "Bigram: \"başbakan abdullah\", Olasılık: 0.00013678176469443003\n",
      "Bigram: \"bir türlü\", Olasılık: 0.00013478495061129968\n",
      "Bigram: \"aynı zamanda\", Olasılık: 0.0001337865435697345\n",
      "Bigram: \"belirterek ``\", Olasılık: 0.00013178972948660412\n",
      "Bigram: \"bir şeyler\", Olasılık: 0.00013079132244503893\n",
      "Bigram: \"en önemli\", Olasılık: 0.00012879450836190859\n",
      "Bigram: \"devlet bakanı\", Olasılık: 0.00012829530484112598\n",
      "Bigram: \"yıl önce\", Olasılık: 0.0001272968977995608\n",
      "Bigram: \"... bir\", Olasılık: 0.0001267976942787782\n",
      "Bigram: \"en az\", Olasılık: 0.00012579928723721302\n",
      "Bigram: \"bu yıl\", Olasılık: 0.00012330326963330007\n",
      "Bigram: \"her gün\", Olasılık: 0.00012130645555016971\n",
      "Bigram: \"ancak bu\", Olasılık: 0.00012130645555016971\n",
      "Bigram: \"abdullah gül\", Olasılık: 0.00012080725202938712\n",
      "Bigram: \"şunları söyledi\", Olasılık: 0.00011980884498782193\n",
      "Bigram: \"... ``\", Olasılık: 0.00011930964146703934\n",
      "Bigram: \"genel başkan\", Olasılık: 0.00011881043794625674\n",
      "Bigram: \"her türlü\", Olasılık: 0.00011831123442547415\n",
      "Bigram: \"olan bir\", Olasılık: 0.00011781203090469157\n",
      "Bigram: \"küçük bir\", Olasılık: 0.0001158152168215612\n",
      "Bigram: \"... bu\", Olasılık: 0.0001158152168215612\n",
      "Bigram: \"türkiye ’\", Olasılık: 0.0001158152168215612\n",
      "Bigram: \"iyi bir\", Olasılık: 0.00011381840273843083\n",
      "Bigram: \"var ki\", Olasılık: 0.00011331919921764824\n",
      "Bigram: \"ki bu\", Olasılık: 0.00011281999569686565\n",
      "Bigram: \"biz de\", Olasılık: 0.00011182158865530047\n",
      "Bigram: \"çok önemli\", Olasılık: 0.0001098247745721701\n",
      "Bigram: \"yönetim kurulu\", Olasılık: 0.0001098247745721701\n",
      "Bigram: \"en iyi\", Olasılık: 0.0001093255710513875\n",
      "Bigram: \"var mı\", Olasılık: 0.00010882636753060493\n",
      "Bigram: \"sık sık\", Olasılık: 0.00010832716400982233\n",
      "Bigram: \"en azından\", Olasılık: 0.00010782796048903974\n",
      "Bigram: \"ne zaman\", Olasılık: 0.00010732875696825715\n",
      "Bigram: \"ve ``\", Olasılık: 0.00010732875696825715\n",
      "Bigram: \"... ama\", Olasılık: 0.00010682955344747455\n",
      "Bigram: \"zaman zaman\", Olasılık: 0.00010633034992669196\n",
      "Bigram: \"bir araya\", Olasılık: 0.00010633034992669196\n",
      "Bigram: \"onun için\", Olasılık: 0.00010583114640590937\n",
      "Bigram: \"son derece\", Olasılık: 0.00010583114640590937\n",
      "Bigram: \"biraz daha\", Olasılık: 0.00010533194288512679\n",
      "Bigram: \"milyon dolar\", Olasılık: 0.00010283592528121382\n",
      "Bigram: \"söyledi ``\", Olasılık: 0.00010233672176043124\n",
      "Bigram: \"'' diye\", Olasılık: 0.00010183751823964864\n",
      "Bigram: \"ne var\", Olasılık: 0.00010133831471886605\n",
      "Bigram: \"ile birlikte\", Olasılık: 0.00010133831471886605\n",
      "Bigram: \"hiçbir zaman\", Olasılık: 0.00010083911119808346\n",
      "Bigram: \"süre sonra\", Olasılık: 0.00010033990767730086\n",
      "Bigram: \"başbakan yardımcısı\", Olasılık: 0.00010033990767730086\n",
      "Bigram: \"bunun için\", Olasılık: 9.984070415651827e-05\n",
      "Bigram: \"bir yıl\", Olasılık: 9.934150063573569e-05\n",
      "Bigram: \"`` bir\", Olasılık: 9.83430935941705e-05\n",
      "Bigram: \"bir kadın\", Olasılık: 9.684548303182272e-05\n",
      "Bigram: \"kez daha\", Olasılık: 9.634627951104013e-05\n",
      "Bigram: \"şöyle konuştu\", Olasılık: 9.634627951104013e-05\n",
      "Bigram: \"o gün\", Olasılık: 9.584707599025755e-05\n",
      "Bigram: \"öte yandan\", Olasılık: 9.584707599025755e-05\n",
      "Bigram: \"dışişleri bakanı\", Olasılık: 9.534787246947496e-05\n",
      "Bigram: \"akp lideri\", Olasılık: 9.534787246947496e-05\n",
      "Bigram: \"mahk û\", Olasılık: 9.484866894869236e-05\n",
      "Bigram: \"güzel bir\", Olasılık: 9.335105838634458e-05\n",
      "Bigram: \"ilgili olarak\", Olasılık: 9.335105838634458e-05\n",
      "Bigram: \"da ``\", Olasılık: 9.335105838634458e-05\n",
      "Bigram: \"tek başına\", Olasılık: 9.2851854865562e-05\n",
      "Bigram: \"tek bir\", Olasılık: 9.2851854865562e-05\n",
      "Bigram: \"de ``\", Olasılık: 9.185344782399681e-05\n",
      "Bigram: \"bir iki\", Olasılık: 9.135424430321422e-05\n",
      "Bigram: \"milli eğitim\", Olasılık: 9.085504078243163e-05\n",
      "Bigram: \"akp genel\", Olasılık: 9.085504078243163e-05\n",
      "Bigram: \"yavaş yavaş\", Olasılık: 9.035583726164903e-05\n",
      "Bigram: \"3 kasım\", Olasılık: 8.935743022008386e-05\n",
      "Bigram: \"i̇stanbul a\", Olasılık: 8.835902317851867e-05\n",
      "Bigram: \"öyle bir\", Olasılık: 8.835902317851867e-05\n",
      "Bigram: \"nasıl bir\", Olasılık: 8.835902317851867e-05\n",
      "Bigram: \"sonuna kadar\", Olasılık: 8.835902317851867e-05\n",
      "Bigram: \"özel bir\", Olasılık: 8.835902317851867e-05\n",
      "Bigram: \"ifade eden\", Olasılık: 8.785981965773608e-05\n",
      "Bigram: \"bir tek\", Olasılık: 8.736061613695349e-05\n",
      "Bigram: \"’ nın\", Olasılık: 8.736061613695349e-05\n",
      "Bigram: \"diye sordu\", Olasılık: 8.636220909538831e-05\n",
      "Bigram: \"diye bir\", Olasılık: 8.636220909538831e-05\n",
      "Bigram: \"benim için\", Olasılık: 8.586300557460572e-05\n",
      "Bigram: \"bir yer\", Olasılık: 8.586300557460572e-05\n",
      "Bigram: \"bugüne kadar\", Olasılık: 8.586300557460572e-05\n",
      "Bigram: \"genel müdürü\", Olasılık: 8.586300557460572e-05\n",
      "Bigram: \"yıl sonra\", Olasılık: 8.486459853304053e-05\n",
      "Bigram: \"bu iki\", Olasılık: 8.486459853304053e-05\n",
      "Bigram: \"ama o\", Olasılık: 8.436539501225794e-05\n",
      "Bigram: \"... o\", Olasılık: 8.436539501225794e-05\n",
      "Bigram: \"`` ``\", Olasılık: 8.436539501225794e-05\n",
      "Bigram: \"bir biçimde\", Olasılık: 8.386619149147535e-05\n",
      "Bigram: \"geçen yıl\", Olasılık: 8.386619149147535e-05\n",
      "Bigram: \"bir insan\", Olasılık: 8.386619149147535e-05\n",
      "Bigram: \"için bu\", Olasılık: 8.386619149147535e-05\n",
      "Bigram: \"kısa bir\", Olasılık: 8.336698797069277e-05\n",
      "Bigram: \"belli bir\", Olasılık: 8.336698797069277e-05\n",
      "Bigram: \"bir ara\", Olasılık: 8.336698797069277e-05\n",
      "Bigram: \"olduğunu söyledi\", Olasılık: 8.286778444991017e-05\n",
      "Bigram: \"başbakan gül\", Olasılık: 8.236858092912758e-05\n",
      "Bigram: \"’ a\", Olasılık: 8.137017388756239e-05\n",
      "Bigram: \"`` diyen\", Olasılık: 8.08709703667798e-05\n",
      "Bigram: \"devam etti\", Olasılık: 8.037176684599722e-05\n",
      "Bigram: \"`` diyor\", Olasılık: 7.937335980443203e-05\n",
      "Bigram: \"ama bir\", Olasılık: 7.887415628364944e-05\n",
      "Bigram: \"olursa olsun\", Olasılık: 7.837495276286684e-05\n",
      "Bigram: \"ifade etti\", Olasılık: 7.837495276286684e-05\n",
      "Bigram: \"çok sayıda\", Olasılık: 7.787574924208425e-05\n",
      "Bigram: \"bu bir\", Olasılık: 7.787574924208425e-05\n",
      "Bigram: \"de çok\", Olasılık: 7.787574924208425e-05\n",
      "Bigram: \"bir anda\", Olasılık: 7.737654572130166e-05\n",
      "Bigram: \"devam ediyor\", Olasılık: 7.737654572130166e-05\n",
      "Bigram: \"milyar lira\", Olasılık: 7.687734220051908e-05\n",
      "Bigram: \"tayyip erdoğan'ın\", Olasılık: 7.687734220051908e-05\n",
      "Bigram: \"bir yerde\", Olasılık: 7.637813867973648e-05\n",
      "Bigram: \"tam bir\", Olasılık: 7.637813867973648e-05\n",
      "Bigram: \"o gece\", Olasılık: 7.637813867973648e-05\n",
      "Bigram: \"yandan da\", Olasılık: 7.587893515895389e-05\n",
      "Bigram: \"bin lira\", Olasılık: 7.587893515895389e-05\n",
      "Bigram: \"konuştu ``\", Olasılık: 7.587893515895389e-05\n",
      "Bigram: \"ve daha\", Olasılık: 7.53797316381713e-05\n",
      "Bigram: \"erdoğan ``\", Olasılık: 7.53797316381713e-05\n",
      "Bigram: \"... ne\", Olasılık: 7.48805281173887e-05\n",
      "Bigram: \"bir kere\", Olasılık: 7.48805281173887e-05\n",
      "Bigram: \"olarak da\", Olasılık: 7.438132459660611e-05\n",
      "Bigram: \"ve her\", Olasılık: 7.388212107582353e-05\n",
      "Bigram: \"sonra bir\", Olasılık: 7.338291755504094e-05\n",
      "Bigram: \"önceki gün\", Olasılık: 7.338291755504094e-05\n",
      "Bigram: \"`` türkiye\", Olasılık: 7.338291755504094e-05\n",
      "Bigram: \"uzun bir\", Olasılık: 7.288371403425834e-05\n",
      "Bigram: \"’ e\", Olasılık: 7.288371403425834e-05\n",
      "Bigram: \"... ve\", Olasılık: 7.238451051347575e-05\n",
      "Bigram: \"çok büyük\", Olasılık: 7.238451051347575e-05\n",
      "Bigram: \"mehmet ali\", Olasılık: 7.238451051347575e-05\n",
      "Bigram: \"telefon numarası\", Olasılık: 7.238451051347575e-05\n",
      "Bigram: \"olan bu\", Olasılık: 7.188530699269316e-05\n",
      "Bigram: \"de olsa\", Olasılık: 7.138610347191056e-05\n",
      "Bigram: \"ne yazık\", Olasılık: 7.138610347191056e-05\n",
      "Bigram: \"yazık ki\", Olasılık: 7.138610347191056e-05\n",
      "Bigram: \"trilyon lira\", Olasılık: 7.138610347191056e-05\n",
      "Bigram: \"`` olarak\", Olasılık: 7.138610347191056e-05\n",
      "Bigram: \"ve o\", Olasılık: 7.088689995112798e-05\n",
      "Bigram: \"bir gece\", Olasılık: 7.038769643034539e-05\n",
      "Bigram: \"bundan sonra\", Olasılık: 7.038769643034539e-05\n",
      "Bigram: \"biraz da\", Olasılık: 7.038769643034539e-05\n",
      "Bigram: \"en yüksek\", Olasılık: 7.038769643034539e-05\n",
      "Bigram: \"ortaya çıktı\", Olasılık: 7.038769643034539e-05\n",
      "Bigram: \"şöyle bir\", Olasılık: 6.93892893887802e-05\n",
      "Bigram: \"bütün bu\", Olasılık: 6.93892893887802e-05\n",
      "Bigram: \"bir yana\", Olasılık: 6.839088234721501e-05\n",
      "Bigram: \"erdoğan a\", Olasılık: 6.839088234721501e-05\n",
      "Bigram: \"bir çocuk\", Olasılık: 6.739247530564984e-05\n",
      "Bigram: \"bir yere\", Olasılık: 6.739247530564984e-05\n",
      "Bigram: \"daha doğrusu\", Olasılık: 6.739247530564984e-05\n",
      "Bigram: \"dünyanın en\", Olasılık: 6.739247530564984e-05\n",
      "Bigram: \"ciddi bir\", Olasılık: 6.739247530564984e-05\n",
      "Bigram: \"için çok\", Olasılık: 6.639406826408465e-05\n",
      "Bigram: \"û m\", Olasılık: 6.639406826408465e-05\n",
      "Bigram: \"ak parti\", Olasılık: 6.639406826408465e-05\n",
      "Bigram: \"ki ...\", Olasılık: 6.589486474330206e-05\n",
      "Bigram: \"var bu\", Olasılık: 6.589486474330206e-05\n",
      "Bigram: \"başkan yardımcısı\", Olasılık: 6.589486474330206e-05\n",
      "Bigram: \"olmayan bir\", Olasılık: 6.539566122251947e-05\n"
     ]
    }
   ],
   "source": [
    "# Her bir bigramın olasılıklarını hesapla ve bir listeye kaydet\n",
    "toplam_bigram = sum(bigram_freq.values())\n",
    "\n",
    "bigram_olasiliklari = [(bigram, sayi / toplam_bigram) for bigram, sayi in bigram_freq.items()]\n",
    "\n",
    "# Olasılıklara göre büyükten küçüğe sıralama\n",
    "bigram_olasiliklari.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# En olası 50 bigramı gösterelim\n",
    "en_olasi_50 = bigram_olasiliklari[:250]\n",
    "\n",
    "# En olası 50 bigramı yazdırma\n",
    "for bigram, olasilik in en_olasi_50:\n",
    "    print(f\"Bigram: \\\"{bigram[0]} {bigram[1]}\\\", Olasılık: {olasilik}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e34b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import string\n",
    "import math\n",
    "\n",
    "# Gerekli nltk verilerini indirme\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Metin dosyasını okuma\n",
    "with open(\"dosyalar\\odtu_derlemi.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    metin = file.read()\n",
    "\n",
    "# Metni kelime seviyesinde tokenize et\n",
    "kelimeler = nltk.word_tokenize(metin.lower())\n",
    "\n",
    "# Noktalama işaretlerinden kurtulma\n",
    "kelimeler = [kelime for kelime in kelimeler if kelime not in string.punctuation]\n",
    "\n",
    "# 2-gram (Bigram) modelini oluştur\n",
    "bigramlar = list(ngrams(kelimeler, 2))\n",
    "\n",
    "# Bigramların frekansını hesapla\n",
    "bigram_freq = Counter(bigramlar)\n",
    "\n",
    "# Unigramların frekansını hesapla\n",
    "unigram_freq = Counter(kelimeler)\n",
    "\n",
    "# Toplam unigram ve bigram sayısını al\n",
    "toplam_unigram = sum(unigram_freq.values())\n",
    "toplam_bigram = sum(bigram_freq.values())\n",
    "\n",
    "# Verilen bir cümlenin bigram zinciri olasılığını hesaplama\n",
    "def cumlenin_olasiligini_hesapla(cumle):\n",
    "    # Cümleyi tokenize et ve noktalama işaretlerinden kurtul\n",
    "    kelimeler = nltk.word_tokenize(cumle.lower())\n",
    "    kelimeler = [kelime for kelime in kelimeler if kelime not in string.punctuation]\n",
    "    \n",
    "    # İlk kelimenin unigram olasılığı\n",
    "    ilk_kelime = kelimeler[0]\n",
    "    if ilk_kelime in unigram_freq:\n",
    "        olasilik = unigram_freq[ilk_kelime] / toplam_unigram\n",
    "    else:\n",
    "        olasilik = 1 / toplam_unigram  # Eğer ilk kelime yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    # Sonraki kelimeler için bigram olasılıklarını çarp\n",
    "    for i in range(1, len(kelimeler)):\n",
    "        onceki_kelime = kelimeler[i - 1]\n",
    "        simdiki_kelime = kelimeler[i]\n",
    "        bigram = (onceki_kelime, simdiki_kelime)\n",
    "        \n",
    "        if bigram in bigram_freq:\n",
    "            olasilik *= bigram_freq[bigram] / unigram_freq[onceki_kelime]\n",
    "        else:\n",
    "            olasilik *= 1 / toplam_bigram  # Eğer bigram yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    return olasilik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a8be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cümlesi\n",
    "cumle = \"hafta sonu sinemaya gidelim\"\n",
    "olasilik = cumlenin_olasiligini_hesapla(cumle)\n",
    "\n",
    "print(f\"'{cumle}' cümlesinin olasılığı: {olasilik}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50507b4b",
   "metadata": {},
   "source": [
    "Yukarıda Markov zinciri formülü yardımıyla bigram'leri kullanarak cümle olasılıklarını hesapladık. Ancak bigram olasılıklarını çarptığımız için daha uzun cümlelerin olasılıkları daha düşük olacaktır. Bu handikaptan kurtulmak için log-olasılıkları hesaplayalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bfbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verilen bir cümlenin logaritmik bigram zinciri olasılığını hesaplama\n",
    "def cumlenin_log_olasiligini_hesapla(cumle):\n",
    "    # Cümleyi tokenize et ve noktalama işaretlerinden kurtul\n",
    "    kelimeler = nltk.word_tokenize(cumle.lower())\n",
    "    kelimeler = [kelime for kelime in kelimeler if kelime not in string.punctuation]\n",
    "    \n",
    "    # İlk kelimenin unigram olasılığı\n",
    "    ilk_kelime = kelimeler[0]\n",
    "    if ilk_kelime in unigram_freq:\n",
    "        log_olasilik = math.log(unigram_freq[ilk_kelime] / toplam_unigram)\n",
    "    else:\n",
    "        log_olasilik = math.log(1 / toplam_unigram)  # Eğer ilk kelime yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    # Sonraki kelimeler için bigram log olasılıklarını toplama\n",
    "    for i in range(1, len(kelimeler)):\n",
    "        onceki_kelime = kelimeler[i - 1]\n",
    "        simdiki_kelime = kelimeler[i]\n",
    "        bigram = (onceki_kelime, simdiki_kelime)\n",
    "        \n",
    "        if bigram in bigram_freq:\n",
    "            log_olasilik += math.log(bigram_freq[bigram] / unigram_freq[onceki_kelime])\n",
    "        else:\n",
    "            log_olasilik += math.log(1 / toplam_bigram)  # Eğer bigram yoksa çok küçük bir olasılık ver\n",
    "    \n",
    "    return log_olasilik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d35d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test için bir dizi cümle\n",
    "cumleler = [\n",
    "    \"hafta sonu sinemaya gidelim\",\n",
    "    \"hafta sonu sinemaya gidersek\",\n",
    "    \"hafta sonu sinemaya gittik\",\n",
    "    \"hafta sonu sinemaya gideceğiz\"\n",
    "]\n",
    "\n",
    "# Her bir cümle için logaritmik olasılığı hesapla ve yazdır\n",
    "for cumle in cumleler:\n",
    "    log_olasilik = cumlenin_log_olasiligini_hesapla(cumle)\n",
    "    print(f\"'{cumle}' cümlesinin logaritmik olasılığı: {log_olasilik}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d3e13",
   "metadata": {},
   "source": [
    "herhangi bir ikilinin ikili sıklık listesinde olup olmadığına bakabiliriz, listede olmayan ikililer cümlenin olasılığını düşürür:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c665e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = (\"sinemaya\", \"gidelim\")\n",
    "        \n",
    "if bigram in bigram_freq:\n",
    "    print(\"var\")\n",
    "else:\n",
    "    print(\"yok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b546a5",
   "metadata": {},
   "source": [
    "n-gram dil modellerini kullanarak bir kelimeden sonra gelebilecek en olası kelimeyi bulabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd79c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonraki_kelimeyi_tahmin_et(baslangic_kelimesi, bigram_freq):\n",
    "    olasi_bigramlar = {bigram: freq for bigram, freq in bigram_freq.items() if bigram[0] == baslangic_kelimesi}\n",
    "    en_olasi_bigram = max(olasi_bigramlar, key=olasi_bigramlar.get) if olasi_bigramlar else None\n",
    "    if en_olasi_bigram:\n",
    "        return en_olasi_bigram[1]\n",
    "    return None\n",
    "\n",
    "baslangic = \"üniversite\"\n",
    "sonraki_kelime = sonraki_kelimeyi_tahmin_et(baslangic, bigram_freq)\n",
    "print(f\"'{baslangic}' kelimesinden sonra en olası kelime: {sonraki_kelime}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metin_olustur(baslangic_kelime, bigram_freq, n=10):\n",
    "    metin = [baslangic_kelime]\n",
    "    for _ in range(n):\n",
    "        sonraki_kelime = sonraki_kelimeyi_tahmin_et(metin[-1], bigram_freq)\n",
    "        if sonraki_kelime:\n",
    "            metin.append(sonraki_kelime)\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(metin)\n",
    "\n",
    "baslangic = \"üniversite\"\n",
    "uretilen_metin = metin_olustur(baslangic, bigram_freq)\n",
    "print(f\"Oluşturulan metin: {uretilen_metin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f122619b",
   "metadata": {},
   "source": [
    "Metin üretiminde özellikle deterministik yaklaşımlar kullanıldığında (yani her zaman en yüksek olasılıklı kelimenin seçilmesi) sürekli aynı kelime dizisine ulaşılabilir. Bundan kaçınmak için aşağıdaki gibi rastsallık eklenebilir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b67c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sonraki_kelimeyi_rastsal_tahmin_et(baslangic_kelimesi, bigram_freq):\n",
    "    olasi_bigramlar = {bigram: freq for bigram, freq in bigram_freq.items() if bigram[0] == baslangic_kelimesi}\n",
    "    \n",
    "    if not olasi_bigramlar:\n",
    "        return None\n",
    "    \n",
    "    bigramlar = list(olasi_bigramlar.keys())\n",
    "    frekanslar = list(olasi_bigramlar.values())\n",
    "    \n",
    "    # Bigram olasılıklarını normalize etme\n",
    "    toplam_frekans = sum(frekanslar)\n",
    "    olasiliklar = [freq / toplam_frekans for freq in frekanslar]\n",
    "    \n",
    "    # Olasılıklara dayalı rastgele seçim yap\n",
    "    secilen_bigram = random.choices(bigramlar, weights=olasiliklar, k=1)[0]\n",
    "    return secilen_bigram[1]\n",
    "\n",
    "# Rastsal kelime seçimi ile metin oluşturma\n",
    "def metin_olustur_rastsal(baslangic_kelime, bigram_freq, n=10):\n",
    "    metin = [baslangic_kelime]\n",
    "    for _ in range(n):\n",
    "        sonraki_kelime = sonraki_kelimeyi_rastsal_tahmin_et(metin[-1], bigram_freq)\n",
    "        if sonraki_kelime:\n",
    "            metin.append(sonraki_kelime)\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(metin)\n",
    "\n",
    "# Test için metin oluşturma\n",
    "baslangic = \"üniversite\"\n",
    "uretilen_metin = metin_olustur_rastsal(baslangic, bigram_freq)\n",
    "print(f\"Oluşturulan metin: {uretilen_metin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5161bf",
   "metadata": {},
   "source": [
    "N-gram modelleri yazım hatası olan kelimeleri düzeltebilir. Bir kelime yanlış yazıldığında, model bir kelimenin en çok hangi kelimeyle eşleştiğini bulabilir ve hatalı kelime yerine doğrusunu önerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6510835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hatalı bir kelimeyi düzeltmek için benzer kelimeleri bulma (Levenshtein mesafesi veya basit bir yakınlık ölçüsü kullanarak)\n",
    "def kelime_duzeltme(hatali_kelime, unigram_freq):\n",
    "    # Levenshtein mesafesi (hamming distance gibi) kullanmak daha gelişmiş olabilir, ancak burada basit bir benzerlik ölçüsü kullanıyoruz.\n",
    "    def benzerlik(kelime1, kelime2):\n",
    "        # Aynı uzunluktaki kelimeler daha olasıdır\n",
    "        if abs(len(kelime1) - len(kelime2)) > 2:\n",
    "            return 0\n",
    "        # Harflerin ne kadarının eşleştiğine bakarak basit bir benzerlik skoru verelim\n",
    "        return sum(1 for a, b in zip(kelime1, kelime2) if a == b)\n",
    "\n",
    "    # Tüm unigramlar içinde hatalı kelimeye en çok benzeyen kelimeleri bulalım\n",
    "    en_benzer_kelime = max(unigram_freq.keys(), key=lambda kelime: benzerlik(hatali_kelime, kelime))\n",
    "    return en_benzer_kelime\n",
    "\n",
    "# Test cümlesi: Hatalı bir kelime ile\n",
    "hatali_cumle = \"yarın hava sırak olacak\"\n",
    "cumledeki_kelime = \"sırak\"\n",
    "\n",
    "# Düzeltme önerisi\n",
    "duzeltilmis_kelime = kelime_duzeltme(cumledeki_kelime, unigram_freq)\n",
    "\n",
    "print(f\"Hatalı kelime: {cumledeki_kelime}, Düzeltme önerisi: {duzeltilmis_kelime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd88ba",
   "metadata": {},
   "source": [
    "İmla düzeltme işleminde önceki ve sonraki kelimeyi hesaba katarsak model çok daha güçlü hale gelir: (Ayrıca iki kelime arasındaki harflerin birebir eşleşmesine bakarak basit bir benzerlik skoru hesaplama yerine Levenshtein mesafesini kullanalım)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilgili kütüphaneyi yüklemek için bu kodu bir kez çalıştırmalıyız:\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "# Hatalı bir kelimeyi düzelten fonksiyon (bağlama duyarlı)\n",
    "def kelime_duzeltme_bağlam(hatali_kelime, onceki_kelime, sonraki_kelime, unigram_freq, bigram_freq):\n",
    "    # Basit benzerlik ölçümü: Aynı uzunluktaki kelimeler daha olasıdır, harf eşleşmelerine bakıyoruz\n",
    "    def benzerlik(kelime1, kelime2):\n",
    "        if abs(len(kelime1) - len(kelime2)) > 2:\n",
    "            return 0\n",
    "        return sum(1 for a, b in zip(kelime1, kelime2) if a == b)\n",
    "\n",
    "    # Hataya en benzer kelimeleri bulalım\n",
    "    #olasi_duzeltmeler = sorted(unigram_freq.keys(), key=lambda kelime: benzerlik(hatali_kelime, kelime), reverse=True)[:50]\n",
    "    olasi_duzeltmeler = sorted(unigram_freq.keys(), key=lambda kelime: Levenshtein.distance(hatali_kelime, kelime))[:50]\n",
    "\n",
    "    # Bigram olasılıklarını hesaba katarak en olası kelimeyi seç\n",
    "    en_iyi_kelime = None\n",
    "    en_yuksek_olasilik = 0\n",
    "\n",
    "    for duzeltme in olasi_duzeltmeler:\n",
    "        # Önceki ve sonraki kelimelerle bigram oluşturma\n",
    "        bigram_olasilik = 1\n",
    "        if onceki_kelime and (onceki_kelime, duzeltme) in bigram_freq:\n",
    "            bigram_olasilik *= bigram_freq[(onceki_kelime, duzeltme)] / unigram_freq[onceki_kelime]\n",
    "        else:\n",
    "            bigram_olasilik *= 0.0001  # Eğer bigram yoksa küçük bir olasılık verelim\n",
    "        \n",
    "        if sonraki_kelime and (duzeltme, sonraki_kelime) in bigram_freq:\n",
    "            bigram_olasilik *= bigram_freq[(duzeltme, sonraki_kelime)] / unigram_freq[duzeltme]\n",
    "        else:\n",
    "            bigram_olasilik *= 0.0001  # Eğer bigram yoksa küçük bir olasılık verelim\n",
    "\n",
    "        # En yüksek olasılığa sahip kelimeyi seç\n",
    "        if bigram_olasilik > en_yuksek_olasilik:\n",
    "            en_yuksek_olasilik = bigram_olasilik\n",
    "            en_iyi_kelime = duzeltme\n",
    "        #print(duzeltme + \" \" + str(bigram_olasilik))\n",
    "    return en_iyi_kelime\n",
    "\n",
    "# Test cümlesi: Hatalı bir kelimeyle birlikte\n",
    "hatali_cumle = \"yarın hava sırak olacak\"\n",
    "cumle_tokens = nltk.word_tokenize(hatali_cumle.lower())\n",
    "\n",
    "# Hatalı kelime ve çevresindeki kelimeler\n",
    "target = 2\n",
    "hatali_kelime = cumle_tokens[target]\n",
    "onceki_kelime = cumle_tokens[target-1]\n",
    "sonraki_kelime = cumle_tokens[target+1]\n",
    "\n",
    "# Düzeltme önerisi\n",
    "duzeltilmis_kelime = kelime_duzeltme_bağlam(hatali_kelime, onceki_kelime, sonraki_kelime, unigram_freq, bigram_freq)\n",
    "\n",
    "print(f\"Hatalı kelime: {hatali_kelime}, Düzeltme önerisi: {duzeltilmis_kelime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81909596",
   "metadata": {},
   "source": [
    "n-gram'ler kullanılarak metin özeti oluşturulabilir. aşağıdaki kodda büyük bir metin dosyası n-gram'leri oluşturmak için kullanılıyor ve başka bir metin dosyası ile sağlanan metinden hesaplanan en sık 50 bigram'i içeren cümleler seçilerek özet elde ediliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9db2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "# Gerekli nltk verilerini indirme\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Büyük metin dosyasını okuma ve N-gram frekanslarını hesaplama\n",
    "def ngram_frekanslari_olustur(dosya_adi, n=2):\n",
    "    with open(dosya_adi, \"r\", encoding=\"utf-8\") as file:\n",
    "        metin = file.read()\n",
    "    \n",
    "    # Metni kelime seviyesinde tokenize et ve noktalama işaretlerinden kurtul\n",
    "    kelimeler = nltk.word_tokenize(metin.lower())\n",
    "    kelimeler = [kelime for kelime in kelimeler if kelime not in string.punctuation]\n",
    "    \n",
    "    # N-gram modelini oluştur (varsayılan olarak trigram)\n",
    "    ngramlar = list(ngrams(kelimeler, n))\n",
    "    \n",
    "    # N-gram frekansını hesapla\n",
    "    ngram_freq = Counter(ngramlar)\n",
    "    \n",
    "    return ngram_freq\n",
    "\n",
    "# Özetlenecek metni okuma ve özet oluşturma\n",
    "def metin_ozeti_olustur(dosya_adi, ngram_freq, n=2):\n",
    "    with open(dosya_adi, \"r\", encoding=\"utf-8\") as file:\n",
    "        metin = file.read()\n",
    "    \n",
    "    # Metni cümle seviyesinde tokenize et\n",
    "    cumleler = nltk.sent_tokenize(metin)\n",
    "    \n",
    "    # En sık kullanılan N-gramları seçme\n",
    "    frequent_ngramlar = ngram_freq.most_common(50)\n",
    "    \n",
    "    # N-gram temelli metin özetleme: En sık N-gramların geçtiği cümleleri seç\n",
    "    ozet = []\n",
    "    for ngram in frequent_ngramlar:\n",
    "        #print(ngram)\n",
    "        # N-gramdaki kelimeleri birleştirip arama yapacağız\n",
    "        ngram_kelime = ' '.join(ngram[0])\n",
    "        for cumle in cumleler:\n",
    "            if ngram_kelime in cumle.lower() and cumle not in ozet:\n",
    "                ozet.append(cumle)\n",
    "                break\n",
    "    \n",
    "    return ' '.join(ozet)\n",
    "\n",
    "# Büyük metin dosyasından N-gram frekansları oluşturma\n",
    "ngram_freq = ngram_frekanslari_olustur(\"dosyalar\\odtu_derlemi.txt\")\n",
    "\n",
    "# Özetlenecek metin dosyasından özet oluşturma\n",
    "ozet = metin_ozeti_olustur(\"dosyalar\\ozetlenecek_metin.txt\", ngram_freq)\n",
    "\n",
    "print(\"Metnin Özeti:\")\n",
    "print(ozet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99ea26",
   "metadata": {},
   "source": [
    "N-gram'ler duygu analizi (sentiment analysis) için kullanılabilir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gerekli nltk verilerini indirme\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Eğitim verilerini CSV dosyasından okuma\n",
    "def csv_den_veri_yukle(dosya_adi):\n",
    "    # CSV dosyasını pandas ile yükle\n",
    "    df = pd.read_csv(dosya_adi)\n",
    "    \n",
    "    # \"text\" ve \"label\" sütunlarını kullan\n",
    "    metinler = df['text'].values\n",
    "    etiketler = df['label'].values\n",
    "    \n",
    "    return metinler, etiketler\n",
    "\n",
    "# Büyük metin dosyasını okuma ve N-gram özelliklerini çıkarma\n",
    "def ngram_vektorizer_olustur(dosya_adi, ngram_range=(1, 2)):\n",
    "    with open(dosya_adi, \"r\", encoding=\"utf-8\") as file:\n",
    "        metin = file.read()\n",
    "    \n",
    "    # Metni cümle seviyesinde tokenize et\n",
    "    cumleler = nltk.sent_tokenize(metin)\n",
    "    \n",
    "    # CountVectorizer ile N-gram'leri çıkar ve dönüştürücü olarak geri döndür\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words='english')\n",
    "    vectorizer.fit(cumleler)\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "# Eğitim verilerini CSV dosyasından yükleme\n",
    "metinler, etiketler = csv_den_veri_yukle(\"sentiment_train.csv\")\n",
    "\n",
    "# N-gram özellikleri çıkaran vektörleştiriciyi büyük metin dosyasından öğrenme\n",
    "vectorizer = ngram_vektorizer_olustur(\"dosyalar\\odtu_derlemi.txt\", ngram_range=(1, 2))\n",
    "\n",
    "# Eğitim verilerinde özellik çıkarımı\n",
    "X = vectorizer.transform(metinler)\n",
    "\n",
    "# Eğitim ve test veri setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, etiketler, test_size=0.3, random_state=42)\n",
    "\n",
    "# Naive Bayes modelini kullanarak eğitim yapma\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test verileri ile tahmin yapma\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Sonuçların doğruluğunu kontrol etme\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Doğruluk: {accuracy:.2f}\")\n",
    "\n",
    "# Yeni cümleler için duygu tahmini yapma\n",
    "yeni_cumleler = [\n",
    "    \"Bu ürün çok güzel\",\n",
    "    \"Film berbattı, zaman kaybıydı\",\n",
    "    \"Yemekler çok lezzetliydi\",\n",
    "    \"Hizmet berbat ve yavaş\",\n",
    "    \"Bilgisayarların içinde işlemci vardır\",\n",
    "    \"Neresinden tutsan elinde kalıyor\",\n",
    "    \"Hangi fişi çekmem gerekiyordu\",\n",
    "    \"Keşke hafızamı kaybetsem de bu kitabı baştan okuyabilsem\"\n",
    "]\n",
    "\n",
    "# Yeni cümleleri N-gram vektörüne dönüştürme ve tahmin etme\n",
    "yeni_ozellikler = vectorizer.transform(yeni_cumleler)\n",
    "yeni_tahminler = model.predict(yeni_ozellikler)\n",
    "\n",
    "# Yeni cümlelerin tahminlerini gösterme\n",
    "for cumle, tahmin in zip(yeni_cumleler, yeni_tahminler):\n",
    "    print(f\"Cümle: '{cumle}' - Tahmin Edilen Duygu: {tahmin}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
