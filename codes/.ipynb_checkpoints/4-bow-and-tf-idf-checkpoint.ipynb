{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bcb3074",
   "metadata": {},
   "source": [
    "Bag-of-Words modeli bir metni kelime frekanslarına göre temsil eden basit bir modeldir. Bu modelde metin içindeki her kelimenin kaç kez geçtiği sayılır ve bu bilgiler bir vektör olarak saklanır. BoW modeli kelimelerin sırasını dikkate almaz, sadece kelime sıklıklarına odaklanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52033672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Vektörleri:\n",
      "   00  000  04  10  100  1000  10000  105  1065  10748  ...  şıkırtıları  \\\n",
      "0   0    0   0   0    0     0      0    0     0      0  ...            0   \n",
      "1   0    0   0   0    0     0      0    0     0      0  ...            0   \n",
      "2   0    0   0   0    0     0      0    0     0      0  ...            0   \n",
      "3   0    0   0   0    0     0      0    0     0      0  ...            0   \n",
      "4   0    0   0   0    0     0      0    0     0      0  ...            0   \n",
      "\n",
      "   şıkırtılarını  şımardıkça  şımartılmıştır  şımarık  şımarıklığıydı  şıp  \\\n",
      "0              0           0               0        0               0    0   \n",
      "1              0           0               0        0               0    0   \n",
      "2              0           0               0        0               0    0   \n",
      "3              0           0               0        0               0    0   \n",
      "4              0           0               0        0               0    0   \n",
      "\n",
      "   şıpır  şırıl  şıvgalarıyla  \n",
      "0      0      0             0  \n",
      "1      0      0             0  \n",
      "2      0      0             0  \n",
      "3      0      0             0  \n",
      "4      0      0             0  \n",
      "\n",
      "[5 rows x 33806 columns]\n",
      "\n",
      "TF-IDF Vektörleri:\n",
      "    00  000   04   10  100  1000  10000  105  1065  10748  ...  şıkırtıları  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  ...          0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  ...          0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  ...          0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  ...          0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0  ...          0.0   \n",
      "\n",
      "   şıkırtılarını  şımardıkça  şımartılmıştır  şımarık  şımarıklığıydı  şıp  \\\n",
      "0            0.0         0.0             0.0      0.0             0.0  0.0   \n",
      "1            0.0         0.0             0.0      0.0             0.0  0.0   \n",
      "2            0.0         0.0             0.0      0.0             0.0  0.0   \n",
      "3            0.0         0.0             0.0      0.0             0.0  0.0   \n",
      "4            0.0         0.0             0.0      0.0             0.0  0.0   \n",
      "\n",
      "   şıpır  şırıl  şıvgalarıyla  \n",
      "0    0.0    0.0           0.0  \n",
      "1    0.0    0.0           0.0  \n",
      "2    0.0    0.0           0.0  \n",
      "3    0.0    0.0           0.0  \n",
      "4    0.0    0.0           0.0  \n",
      "\n",
      "[5 rows x 33806 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Metin dosyasından veri okuma\n",
    "def derlemden_veri_okuma(dosya_adi):\n",
    "    with open(dosya_adi, \"r\", encoding=\"utf-8\") as file:\n",
    "        veri = file.readlines()\n",
    "    # İlk 10.000 cümleyi kullanma (hızlı çalışması için)\n",
    "    veri = [satir.strip() for satir in veri[:10000]]  # 10,000 örnek cümleyle sınırlandırıldı\n",
    "    return veri\n",
    "\n",
    "# Dosya adını belirtin (örneğin \"derlem.txt\")\n",
    "dosya_adi = \"dosyalar//odtu_derlemi.txt\"\n",
    "\n",
    "# Derlemden veri okuma\n",
    "veri = derlemden_veri_okuma(dosya_adi)\n",
    "\n",
    "# Bag-of-Words Modeli\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_bow = vectorizer_bow.fit_transform(veri)\n",
    "\n",
    "# BoW vektörlerini gösterme\n",
    "print(\"Bag-of-Words Vektörleri:\")\n",
    "print(pd.DataFrame(X_bow.toarray(), columns=vectorizer_bow.get_feature_names_out()).head())\n",
    "\n",
    "# TF-IDF Modeli\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(veri)\n",
    "\n",
    "# TF-IDF vektörlerini gösterme\n",
    "print(\"\\nTF-IDF Vektörleri:\")\n",
    "print(pd.DataFrame(X_tfidf.toarray(), columns=vectorizer_tfidf.get_feature_names_out()).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9d445",
   "metadata": {},
   "source": [
    "Cümle bazında vektörleştirme uyguladığımız için cümlelerin benzerliklerini hesaplayabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "529f199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'söğüt ağaç yağmur' cümlesine en yakın 10 cümle (BoW ile):\n",
      "Cümle: 'Yağmur başlar .' - Benzerlik: 0.41\n",
      "Cümle: 'Yağmur yağıyor .' - Benzerlik: 0.41\n",
      "Cümle: 'Yağmur yağar .' - Benzerlik: 0.41\n",
      "Cümle: 'Söğüt ağacının dalları ince ve kaygan olur , hele yağmur yağmayagörsün .' - Benzerlik: 0.37\n",
      "Cümle: 'Yağmur yağardı ansızın .' - Benzerlik: 0.33\n",
      "Cümle: 'Orman , alacakaranlık , yağmur .' - Benzerlik: 0.33\n",
      "Cümle: 'Yağmur , çamur , boşver .' - Benzerlik: 0.33\n",
      "Cümle: 'Dışarıda yağmur yağıyordu .' - Benzerlik: 0.33\n",
      "Cümle: 'Yağmur başladı , başlayacak .' - Benzerlik: 0.33\n",
      "Cümle: 'Ne güzel ağaç , demiş .' - Benzerlik: 0.29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Kullanıcıdan sağlanan cümle\n",
    "yeni_cumle = [\"söğüt ağaç yağmur\"]\n",
    "\n",
    "# Yeni cümleyi vektörleştirme\n",
    "yeni_cumle_vect = vectorizer_bow.transform(yeni_cumle)\n",
    "\n",
    "# Yeni cümle ile tüm cümleler arasındaki benzerlikleri hesaplama\n",
    "benzerlikler = cosine_similarity(yeni_cumle_vect, X_bow).flatten()\n",
    "\n",
    "# En benzer 10 cümleyi bulma\n",
    "en_benzer_indices = benzerlikler.argsort()[-10:][::-1]  # En yüksek benzerlikten başlayarak sıralar\n",
    "\n",
    "# En benzer cümleleri ve benzerliklerini gösterme\n",
    "print(f\"'{yeni_cumle[0]}' cümlesine en yakın 10 cümle (BoW ile):\")\n",
    "for idx in en_benzer_indices:\n",
    "    if benzerlikler[idx] > 0:\n",
    "        print(f\"Cümle: '{veri[idx]}' - Benzerlik: {benzerlikler[idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a14d3d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'söğüt ağaç yağmur' cümlesine en yakın 10 cümle (TF-IDF ile):\n",
      "Cümle: 'Söğüt ağacının dalları ince ve kaygan olur , hele yağmur yağmayagörsün .' - Benzerlik: 0.38\n",
      "Cümle: 'Yağmur başlar .' - Benzerlik: 0.36\n",
      "Cümle: 'Yağmur yağıyor .' - Benzerlik: 0.32\n",
      "Cümle: 'Yağmur yağar .' - Benzerlik: 0.32\n",
      "Cümle: 'Ne güzel ağaç , demiş .' - Benzerlik: 0.31\n",
      "Cümle: 'Yağmur başladı , başlayacak .' - Benzerlik: 0.28\n",
      "Cümle: 'Birden bir yağmur patladı .' - Benzerlik: 0.28\n",
      "Cümle: 'Bu armut ağacı ağaç gibi değil .' - Benzerlik: 0.27\n",
      "Cümle: 'Yağmur yağardı ansızın .' - Benzerlik: 0.27\n",
      "Cümle: 'Bir söğüt ağacıdır hatta , bu yüzden durum daha tehlikelidir .' - Benzerlik: 0.27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# TF-IDF vektörleştirme\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(veri)\n",
    "\n",
    "# Kullanıcıdan sağlanan cümle\n",
    "yeni_cumle = [\"söğüt ağaç yağmur\"]\n",
    "\n",
    "# Yeni cümleyi TF-IDF ile vektörleştirme\n",
    "yeni_cumle_vect = vectorizer_tfidf.transform(yeni_cumle)\n",
    "\n",
    "# Yeni cümle ile tüm cümleler arasındaki benzerlikleri hesaplama\n",
    "benzerlikler = cosine_similarity(yeni_cumle_vect, X_tfidf).flatten()\n",
    "\n",
    "# En benzer 10 cümleyi bulma\n",
    "en_benzer_indices = benzerlikler.argsort()[-10:][::-1]  # En yüksek benzerlikten başlayarak sıralar\n",
    "\n",
    "# En benzer cümleleri ve benzerliklerini gösterme\n",
    "print(f\"'{yeni_cumle[0]}' cümlesine en yakın 10 cümle (TF-IDF ile):\")\n",
    "for idx in en_benzer_indices:\n",
    "    if benzerlikler[idx] > 0:\n",
    "        print(f\"Cümle: '{veri[idx]}' - Benzerlik: {benzerlikler[idx]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60975b6c",
   "metadata": {},
   "source": [
    "Cümle benzerliklerini hesaplamada özellikle BoW modelinin çok başarılı olmadığını görüyoruz. Başarıyı artırmak için hesaplama birimi olarak kelimeleri değil gövdeleri ele alalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TurkishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "709bee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'söğüt ağaç yağmur' cümlesine en yakın 10 cümle (BoW ve TurkishStemmer ile Gövdeleme):\n",
      "Cümle: 'ağaçlı ' - Benzerlik: 0.58\n",
      "Cümle: 'söğüt ağacının dalları ince ve kaygan olur  hele yağmur yağmayagörsün ' - Benzerlik: 0.55\n",
      "Cümle: 'toprağa  mısır tarlalarına  söğüt ağaçlarına hükmeder ' - Benzerlik: 0.47\n",
      "Cümle: 'altına girip yağmurdan sakındığım ağacın da bir koca armut ağacı olduğunu nasıl unuturum ' - Benzerlik: 0.45\n",
      "Cümle: 'yağmur başlar ' - Benzerlik: 0.41\n",
      "Cümle: 'yağmuru seyrediyormuş ' - Benzerlik: 0.41\n",
      "Cümle: 'yağmur yağar ' - Benzerlik: 0.41\n",
      "Cümle: 'yağmur yağıyor ' - Benzerlik: 0.41\n",
      "Cümle: 'bu armut ağacı ağaç gibi değil ' - Benzerlik: 0.41\n",
      "Cümle: 'yağmuru seyrediyorum ' - Benzerlik: 0.41\n",
      "\n",
      "==================================================\n",
      "\n",
      "'söğüt ağaç yağmur' cümlesine en yakın 10 cümle (TF-IDF ve TurkishStemmer ile Gövdeleme):\n",
      "Cümle: 'söğüt ağacının dalları ince ve kaygan olur  hele yağmur yağmayagörsün ' - Benzerlik: 0.54\n",
      "Cümle: 'bir söğüt ağacıdır hatta  bu yüzden durum daha tehlikelidir ' - Benzerlik: 0.51\n",
      "Cümle: 'ağaçlı ' - Benzerlik: 0.48\n",
      "Cümle: 'toprağa  mısır tarlalarına  söğüt ağaçlarına hükmeder ' - Benzerlik: 0.47\n",
      "Cümle: 'yağmur başlar ' - Benzerlik: 0.43\n",
      "Cümle: 'altına girip yağmurdan sakındığım ağacın da bir koca armut ağacı olduğunu nasıl unuturum ' - Benzerlik: 0.37\n",
      "Cümle: 'bu armut ağacı ağaç gibi değil ' - Benzerlik: 0.36\n",
      "Cümle: 'ağacın üstünde ' - Benzerlik: 0.34\n",
      "Cümle: 'uzun sürmüş yağmurlar ' - Benzerlik: 0.32\n",
      "Cümle: 'yağmuru seyrediyormuş ' - Benzerlik: 0.32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "import re\n",
    "\n",
    "# TurkishStemmer kullanarak gövdeleme\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "# Noktalama işaretlerinden temizleme ve küçük harfe çevirme fonksiyonu\n",
    "def temizle(metin):\n",
    "    metin = metin.lower()  # Metni küçük harfe çevirir\n",
    "    metin = re.sub(r'[^\\w\\s]', '', metin)  # Noktalama işaretlerini kaldırır\n",
    "    return metin\n",
    "\n",
    "# Gövdeleme fonksiyonu\n",
    "def turkce_govdeleme(metin):\n",
    "    kelimeler = metin.split()\n",
    "    govdeler = [stemmer.stem(kelime) for kelime in kelimeler]\n",
    "    return ' '.join(govdeler)\n",
    "\n",
    "# Metin dosyasından veri okuma, temizleme ve gövdeleme uygulama\n",
    "def derlemden_veri_okuma(dosya_adi):\n",
    "    with open(dosya_adi, \"r\", encoding=\"utf-8\") as file:\n",
    "        veri = file.readlines()\n",
    "    # İlk 10.000 cümleyi kullanma (hızlı çalışması için)\n",
    "    orijinal_veri = [temizle(satir.strip()) for satir in veri[:10000]]  # Temizlenmiş orijinal metinler\n",
    "    govdeli_veri = [turkce_govdeleme(satir) for satir in orijinal_veri]  # Gövdeleme uygulandı\n",
    "    return orijinal_veri, govdeli_veri\n",
    "\n",
    "# Dosya adını belirtin (örneğin \"odtu_derlemi.txt\")\n",
    "dosya_adi = \"dosyalar//odtu_derlemi.txt\"\n",
    "\n",
    "# Derlemden veri okuma, temizleme ve gövdeleme uygulama\n",
    "orijinal_veri, govdeli_veri = derlemden_veri_okuma(dosya_adi)\n",
    "\n",
    "# TF-IDF Modeli\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(govdeli_veri)\n",
    "\n",
    "# Bag-of-Words Modeli\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_bow = vectorizer_bow.fit_transform(govdeli_veri)\n",
    "\n",
    "# Kullanıcıdan sağlanan cümle\n",
    "yeni_cumle = [\"söğüt ağaç yağmur\"]\n",
    "\n",
    "# Yeni cümleyi temizleme ve gövdeleme uygulama\n",
    "yeni_cumle_temiz = temizle(yeni_cumle[0])\n",
    "yeni_cumle_govdeli = [turkce_govdeleme(yeni_cumle_temiz)]\n",
    "\n",
    "# Yeni cümleyi TF-IDF ile vektörleştirme\n",
    "yeni_cumle_tfidf = vectorizer_tfidf.transform(yeni_cumle_govdeli)\n",
    "\n",
    "# Yeni cümleyi Bag-of-Words ile vektörleştirme\n",
    "yeni_cumle_bow = vectorizer_bow.transform(yeni_cumle_govdeli)\n",
    "\n",
    "# Yeni cümle ile tüm cümleler arasındaki benzerlikleri hesaplama (TF-IDF)\n",
    "benzerlikler_tfidf = cosine_similarity(yeni_cumle_tfidf, X_tfidf).flatten()\n",
    "\n",
    "# Yeni cümle ile tüm cümleler arasındaki benzerlikleri hesaplama (BoW)\n",
    "benzerlikler_bow = cosine_similarity(yeni_cumle_bow, X_bow).flatten()\n",
    "\n",
    "# En benzer 10 cümleyi bulma (TF-IDF)\n",
    "en_benzer_indices_tfidf = benzerlikler_tfidf.argsort()[-10:][::-1]  # En yüksek benzerlikten başlayarak sıralar\n",
    "\n",
    "# En benzer 10 cümleyi bulma (BoW)\n",
    "en_benzer_indices_bow = benzerlikler_bow.argsort()[-10:][::-1]  # En yüksek benzerlikten başlayarak sıralar\n",
    "\n",
    "# En benzer cümleleri ve benzerliklerini orijinal metinlerle gösterme (BoW)\n",
    "print(f\"'{yeni_cumle[0]}' cümlesine en yakın 10 cümle (BoW ve TurkishStemmer ile Gövdeleme):\")\n",
    "for idx in en_benzer_indices_bow:\n",
    "    if benzerlikler_bow[idx] > 0:\n",
    "        print(f\"Cümle: '{orijinal_veri[idx]}' - Benzerlik: {benzerlikler_bow[idx]:.2f}\")\n",
    "        \n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        \n",
    "# En benzer cümleleri ve benzerliklerini orijinal metinlerle gösterme (TF-IDF)\n",
    "print(f\"'{yeni_cumle[0]}' cümlesine en yakın 10 cümle (TF-IDF ve TurkishStemmer ile Gövdeleme):\")\n",
    "for idx in en_benzer_indices_tfidf:\n",
    "    if benzerlikler_tfidf[idx] > 0:\n",
    "        print(f\"Cümle: '{orijinal_veri[idx]}' - Benzerlik: {benzerlikler_tfidf[idx]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de2408",
   "metadata": {},
   "source": [
    "Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97e0851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arama yapmak istediğiniz cümleyi girin: zekadaki\n",
      "'zekadaki' arama sorgusuna en yakın dosyalar:\n",
      "Dosya: 'sağlık.txt' - Benzerlik: 0.16\n",
      "Dosya: 'teknoloji.txt' - Benzerlik: 0.05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "import re\n",
    "\n",
    "# TurkishStemmer kullanarak gövdeleme\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "# Metni temizleme fonksiyonu (lowercase ve noktalama işaretlerinden arındırma)\n",
    "def temizle(metin):\n",
    "    metin = metin.lower()  # Küçük harfe çevirme\n",
    "    metin = re.sub(r'[^\\w\\s]', '', metin)  # Noktalama işaretlerini kaldırma\n",
    "    return metin\n",
    "\n",
    "# Gövdeleme fonksiyonu\n",
    "def turkce_govdeleme(metin):\n",
    "    kelimeler = metin.split()\n",
    "    govdeler = [stemmer.stem(kelime) for kelime in kelimeler]\n",
    "    return ' '.join(govdeler)\n",
    "\n",
    "# Klasördeki metin dosyalarını oku ve temizle\n",
    "def dosyalari_oku_ve_temizle(klasor_adi):\n",
    "    dosyalar = os.listdir(klasor_adi)\n",
    "    metinler = []\n",
    "    dosya_adlari = []\n",
    "    for dosya in dosyalar:\n",
    "        dosya_yolu = os.path.join(klasor_adi, dosya)\n",
    "        with open(dosya_yolu, \"r\", encoding=\"utf-8\") as f:\n",
    "            metin = f.read()\n",
    "            temiz_metin = temizle(metin)\n",
    "            govdeli_metin = turkce_govdeleme(temiz_metin)\n",
    "            metinler.append(govdeli_metin)\n",
    "            dosya_adlari.append(dosya)\n",
    "    return metinler, dosya_adlari\n",
    "\n",
    "# Klasör adı\n",
    "klasor_adi = \"dosyalar//haberler\"\n",
    "\n",
    "# Klasördeki metin dosyalarını oku ve temizle\n",
    "metinler, dosya_adlari = dosyalari_oku_ve_temizle(klasor_adi)\n",
    "\n",
    "# TF-IDF ile metin dosyalarını vektörleştirme\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(metinler)\n",
    "\n",
    "# Kullanıcıdan arama sorgusu al\n",
    "arama_sorgusu = input(\"Arama yapmak istediğiniz cümleyi girin: \")\n",
    "\n",
    "# Arama sorgusunu temizle ve gövdelenmiş hale getir\n",
    "arama_sorgusu_temiz = temizle(arama_sorgusu)\n",
    "arama_sorgusu_govdeli = [turkce_govdeleme(arama_sorgusu_temiz)]\n",
    "\n",
    "# Arama sorgusunu TF-IDF ile vektörleştirme\n",
    "arama_sorgusu_vect = vectorizer_tfidf.transform(arama_sorgusu_govdeli)\n",
    "\n",
    "# Arama sorgusu ile dosyalar arasındaki benzerlikleri hesaplama\n",
    "benzerlikler = cosine_similarity(arama_sorgusu_vect, X_tfidf).flatten()\n",
    "\n",
    "# Benzerliklere göre en iyi eşleşen dosyaları bulma ve sıralama\n",
    "en_benzer_indices = benzerlikler.argsort()[-5:][::-1]  # En yüksek benzerlikten başlayarak sıralar\n",
    "\n",
    "# En benzer dosyaları ve benzerlik oranlarını gösterme\n",
    "print(f\"'{arama_sorgusu}' arama sorgusuna en yakın dosyalar:\")\n",
    "for idx in en_benzer_indices:\n",
    "    if benzerlikler[idx] > 0:\n",
    "        print(f\"Dosya: '{dosya_adlari[idx]}' - Benzerlik: {benzerlikler[idx]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
