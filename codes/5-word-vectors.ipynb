{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e70eb3",
   "metadata": {},
   "source": [
    "# Kelime Vektörleri Nedir?\n",
    "\n",
    "Kelime vektörleri, kelimeleri sürekli sayısal vektörler olarak temsil eder. Bu vektörler kelimeler arasındaki anlamsal ilişkileri yakalamak için kullanılır.\n",
    "\n",
    "Örneğin, \"kral\" ve \"kraliçe\" kelimeleri benzer vektörlere sahip olabilir çünkü semantik olarak ilişkilidirler. \n",
    "Kelime vektörleri, doğal dil işlemede yaygın olarak kullanılır ve metinlerin daha verimli işlenmesini sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff3a8a",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "Word2Vec, Google tarafından geliştirilen ve kelimeleri vektörler halinde temsil eden bir modeldir.\n",
    "\n",
    "İki temel yaklaşımı vardır:\n",
    "- **CBOW (Continuous Bag of Words)**: Verilen bir bağlamdan yola çıkarak hedef kelimeyi tahmin etmeye çalışır.\n",
    "- **Skip-Gram**: Verilen bir kelimeden yola çıkarak bağlamdaki diğer kelimeleri tahmin etmeye çalışır.\n",
    "\n",
    "Word2Vec büyük veri kümelerinde etkili bir şekilde eğitildiğinde kelimeler arasındaki anlamsal benzerlikleri öğrenebilir ve analoji testlerinde başarılı sonuçlar verebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea2edb",
   "metadata": {},
   "source": [
    "# GloVe (Global Vectors for Word Representation)\n",
    "\n",
    "GloVe Stanford Üniversitesi tarafından geliştirilmiş bir kelime vektörü modelidir. \n",
    "\n",
    "Eş-oluşum matrisi üzerine kurulu olan GloVe, kelimelerin metin içerisinde ne sıklıkta bir arada bulunduklarına dayalı olarak vektör temsilleri oluşturur.\n",
    "\n",
    "Bu model kelimelerin daha global bağlamda nasıl ilişkilendirileceğini öğrenir ve genellikle Word2Vec'e göre daha genel ilişkiler yakalayabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510669cc",
   "metadata": {},
   "source": [
    "# FastText\n",
    "FastText, Facebook tarafından geliştirilmiş bir modeldir ve Word2Vec'e benzer şekilde çalışır, ancak alt kelime bilgisi kullanır.\n",
    "\n",
    "FastText, kelimeleri n-gramlar (karakter seviyesinde) şeklinde temsil ederek nadir ve uzun kelimeler için daha iyi temsiller sağlar.\n",
    "\n",
    "Bu özellikle zengin morfolojiye sahip dillerde önemli bir avantajdır ve kelimelerin iç yapılarından faydalanarak daha kapsamlı vektörler oluşturur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcaea5",
   "metadata": {},
   "source": [
    "Word2Vec Uygulaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükleyelim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "\n",
    "# NLTK verilerini indiriyoruz (ilk kullanımda gerekli)\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "# Gutenberg veri setinden bir metin örneği alalım\n",
    "corpus = gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "# Metni tokenize edelim\n",
    "tokenized_text = [word_tokenize(sentence.lower()) for sentence in corpus.split('\\n') if sentence]\n",
    "\n",
    "# İlk birkaç cümleyi görelim\n",
    "print(tokenized_text[:5])\n",
    "\n",
    "# CBOW modelini eğitelim\n",
    "cbow_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=5, sg=0, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek bir kelimenin vektörünü inceleyelim\n",
    "kelime_vektoru = cbow_model.wv['emma']  # 'emma' kelimesinin vektörü\n",
    "print(kelime_vektoru)\n",
    "\n",
    "# Benzer kelimeleri bulalım\n",
    "benzer_kelimeler = cbow_model.wv.most_similar('emma', topn=5)\n",
    "print(benzer_kelimeler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311feb2d",
   "metadata": {},
   "source": [
    "Şimdi de eğitim için kullanılacak metni bir dosyadan okuyalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d61774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükleyelim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Dosyadan metni okuyalım\n",
    "with open('dosyalar//odtu_derlemi.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n",
    "\n",
    "# Metni tokenize edip küçük harfe çevirelim\n",
    "tokenized_text = [word_tokenize(sentence.lower()) for sentence in corpus.split('\\n') if sentence]\n",
    "\n",
    "# İlk birkaç cümleyi görelim\n",
    "print(tokenized_text[:5])\n",
    "\n",
    "# CBOW modelini eğitelim\n",
    "cbow_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=5, sg=0, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee805bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek bir kelimenin vektörünü inceleyelim\n",
    "kelime_vektoru = cbow_model.wv['deniz']\n",
    "print(kelime_vektoru)\n",
    "\n",
    "# Benzer kelimeleri bulalım\n",
    "benzer_kelimeler = cbow_model.wv.most_similar('deniz', topn=5)\n",
    "print(benzer_kelimeler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9aaa83",
   "metadata": {},
   "source": [
    "Şimdi de aynı metinle skipgram modeli eğitelim (sg parametresinin 1 olarak değiştiğine dikkat edin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddb6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkipGram modelini eğitelim\n",
    "skipgram_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=5, sg=1, epochs=10)\n",
    "\n",
    "# Benzer kelimeleri bulalım\n",
    "benzer_kelimeler = skipgram_model.wv.most_similar('deniz', topn=5)\n",
    "print(benzer_kelimeler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5e4a9",
   "metadata": {},
   "source": [
    "Glove Modeli Uygulaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fba0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Hazır GloVe vektörlerini yükleyelim (örnek olarak 50 boyutlu GloVe vektörleri)\n",
    "glove_model = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "# 'emma' kelimesinin vektörünü bulalım\n",
    "kelime_vektoru = glove_model['emma']\n",
    "print(kelime_vektoru)\n",
    "\n",
    "# 'emma' kelimesine benzer diğer kelimeleri bulalım\n",
    "benzer_kelimeler = glove_model.most_similar('emma', topn=5)\n",
    "print(benzer_kelimeler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9495da",
   "metadata": {},
   "source": [
    "FastText Uygulaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd76600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# FastText modelini 10 epoch boyunca eğitelim\n",
    "fasttext_model = FastText(sentences=tokenized_text, vector_size=100, window=5, min_count=5, sg=1, epochs=10)\n",
    "\n",
    "# örnek bir kelimenin vektörünü bulalım\n",
    "fasttext_vektoru = fasttext_model.wv['deniz']\n",
    "print(fasttext_vektoru)\n",
    "\n",
    "# örnek kelimeye benzer diğer kelimeleri bulalım\n",
    "benzer_kelimeler = fasttext_model.wv.most_similar('deniz', topn=5)\n",
    "print(benzer_kelimeler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27677b",
   "metadata": {},
   "source": [
    "Kelime Vektörleri Kullanarak Benzerlik Hesaplama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2347c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "# iki kelime arasındaki kosinüs benzerliğini hesaplayalım\n",
    "word1 = 'kitap'\n",
    "word2 = 'kitaplar'\n",
    "vector1_cbow = cbow_model.wv[word1]\n",
    "vector2_cbow = cbow_model.wv[word2]\n",
    "vector1_skip = skipgram_model.wv[word1]\n",
    "vector2_skip = skipgram_model.wv[word2]\n",
    "vector1_fast = fasttext_model.wv[word1]\n",
    "vector2_fast = fasttext_model.wv[word2]\n",
    "\n",
    "cosine_similarity_cbow = 1 - cosine(vector1_cbow, vector2_cbow)\n",
    "cosine_similarity_skip = 1 - cosine(vector1_skip, vector2_skip)\n",
    "cosine_similarity_fast = 1 - cosine(vector1_fast, vector2_fast)\n",
    "\n",
    "print(f\"'{word1}' ve '{word2}' kelimeleri arasındaki kosinüs benzerlikleri:\\n\")\n",
    "print(f\"cbow      : {cosine_similarity_cbow}\")\n",
    "print(f\"skip-gram : {cosine_similarity_skip}\")\n",
    "print(f\"'fasttext : {cosine_similarity_fast}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3ec0b",
   "metadata": {},
   "source": [
    "Vektör İşlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Word2Vec Türkçe önceden eğitilmiş vektörleri yükleyelim\n",
    "pretrained_word_vectors = KeyedVectors.load_word2vec_format('C:\\\\Users\\\\manue\\\\Desktop\\\\trmodel', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fe26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analoji testi\n",
    "result = pretrained_word_vectors.most_similar(positive=['kral', 'kadın'], negative=['erkek'], topn=30)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5accd575",
   "metadata": {},
   "source": [
    "Kümeleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "# 1. Metni dosyadan yükleme\n",
    "with open('dosyalar//odtu_derlemi.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n",
    "\n",
    "# 2. Metni tokenize edip küçük harfe çevirme\n",
    "tokens = [word.lower() for word in word_tokenize(corpus)]\n",
    "\n",
    "# 3. Kelime frekanslarını hesaplama\n",
    "kelime_frekansları = Counter(tokens)\n",
    "\n",
    "# 4. En sık 100 kelimeyi seçme\n",
    "en_sık_100_kelime = [kelime for kelime, frekans in kelime_frekansları.most_common(100)]\n",
    "\n",
    "# 5. Word2Vec modelini eğitme\n",
    "tokenized_text = [word_tokenize(sentence.lower()) for sentence in corpus.split('\\n') if sentence]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=5, sg=1, epochs=10)\n",
    "\n",
    "# 6. Seçilen kelimelerin vektörlerini çıkarma\n",
    "vektörler = [word2vec_model.wv[kelime] for kelime in en_sık_100_kelime if kelime in word2vec_model.wv]\n",
    "\n",
    "# 7. K-means kümeleme\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(vektörler)\n",
    "\n",
    "# 8. Kelimeleri ve kümeleri yazdırma\n",
    "for kelime, etiket in zip(en_sık_100_kelime, kmeans.labels_):\n",
    "    if kelime in word2vec_model.wv:\n",
    "        print(f\"{kelime}: Küme {etiket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1280f2",
   "metadata": {},
   "source": [
    "Kelime Dışlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_word = pretrained_word_vectors.doesnt_match(['sarı', 'mor', 'kafes', 'yeşil'])\n",
    "print(f\"Uyumsuz kelime: {odd_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4809c1f5",
   "metadata": {},
   "source": [
    "Vektör Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20caf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kelimeler = ['insan', 'kedi', 'köpek', 'okul', 'elektronik', 'bilgisayar']\n",
    "vektörler = [pretrained_word_vectors[word] for word in kelimeler]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(vektörler)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, kelime in enumerate(kelimeler):\n",
    "    plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1])\n",
    "    plt.text(reduced_vectors[i, 0] + 0.01, reduced_vectors[i, 1] + 0.01, kelime)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
